\\\\\\\\\\\\\\\\\\\\\\\\\\\\
ENG
\\\\\\\\\\\\\\\\\\\\\\\\\\\\


What is REST API (HTTP)? SOAP? GraphQL? WebSockets? RPC (gRPC, tRPC). Client-server. All the theory. But why did I combine the HTTP protocol with an architectural style (REST, SOAP) or, say, GraphQL, a query language? Essentially, these are completely different things. And in fact, they’d be partly right. What unites all of this is that it’s a client-server architecture—it defines the way the client and server communicate. About client-server architecture: In this architecture, the server acts as the source of all computations, data storage, some business logic, and clients can interact with this server. That is, there’s a physical machine running our server application, which interacts with the database, defines communication protocols, determines the API, and the client in this entire architecture can communicate with the server through certain actions: it can request some data from it, and the server will return that data. And all this works in a "request-response" format—the client asks for data, the server returns it. And it’s not just about data—we can also tell the server to perform some action, for example, register a new user, process a payment, or add an item to the cart. Accordingly, the server then decides whether it can perform this action or not, and based on that, it will return different responses—meaning the server acts as the single source of computations. At first, I mistakenly thought that the client could just be some browser. But it’s also a mobile app, another server making requests to our server—literally any external contact. Even if we told our smart home to turn on the kettle, that’s already it. So the very term "client-server" implies that the server is the provider of some data, services, logic, and the client is the consumer of that data. For clients, the server is this unified, whole, monolithic-like application, the source of data. But under the hood, the server itself can be large, distributed, made up of multiple microservices—but the client doesn’t really care and shouldn’t have to. About what the entire web is fundamentally built on—HTTP. HTTP is the Hypertext Transfer Protocol, sitting at the very top of the OSI model, the TCP/IP model—the application layer. It’s how most applications on the internet communicate. The original idea of HTTP was the exchange of hypertext documents—our HTML—but now, with HTTP, you can transmit almost any data over the network: text, files, HTML, XML, JSON—basically any format.

About the structure of HTTP itself—for example, a request. If we break down an HTTP request into its components and look at its structure, the first line of the HTTP request is the start line, and it consists of three parts:

Method     URL       HTTP Version
  !         !           !  
POST     /login      HTTP/1.0
The method is, roughly speaking, the semantics of the request—that is, what exactly we want to do: whether we want to create some resource, update it, or retrieve it. In this case, POST indicates that we want to create some resource or simply perform an action.
URL is where we send the request. In this case, we’re sending it to /login—meaning the server understands exactly what action we want to perform.
And then, the HTTP version is specified.

The next part of the HTTP structure is the headers. Headers contain fairly important information. Some headers are mandatory, while others are optional. You can also create your own custom headers.
Host: example.com
Content-Type: application/x-www-form-urlencoded;charset=utf-8
Content-Length: 26
They include information about the host from which the request was sent, details about the browser or device type making the request, the content type (text/html or some other type), as well as various authorization headers with tokens. Additionally, headers ensure security in cross-origin interactions (CORS—headers responsible for secure communication between sources located on different domains).

The third part of an HTTP request—any HTTP request—is the message body itself. Here, the client sends the server any necessary data. For example, in the message, we might send a user’s login and password so the server can identify that user. In other words, the client sends a request that looks like this:
{
  "login": "user",
  "password": "qwerty"
}
And the server must return a response to it.

The response is slightly different from the request:

text
HTTP/1.1 200 OK  
Content-Type: application/json  
Connection: Closed  

{
  "message": "success login",
  "user": { "id": "1", "username": "..." }
}
The start line looks a bit different—in the response, it’s called the status line, and it contains:
The HTTP version, A status code indicating whether the request was successful.
Just like in the request, the response also has headers, but they differ from the request headers (there
are request headers and response headers). And, of course, there’s the message body, where the server
returns data to the client.

HTTP Methods

These are part of the start line in the request. There are many methods, but the main ones developers use
most often are:
GET – Retrieve a resource (e.g., fetch a list of products, users, or detailed info about a specific item).
POST – Send data (create a resource), e.g., auth/login.
PUT – Update a resource (replaces the entire resource).
PATCH – Partially update a resource (only modifies specified fields).
DELETE – Delete a resource (e.g., remove a user or product).
The Status Line (Server Response)
The most important part here is the status code, which tells how the request was processed. There are five
groups of status codes:
Informational (1xx) – Start with 1 (e.g., 100, 101, 102...).
Success (2xx) – Start with 2, meaning the request succeeded.
Example: 201 Created (resource was successfully created).
Redirects (3xx) – Start with 3, usually indicating a redirect (e.g., after login, you’re sent to another
page).
Client Errors (4xx) – Start with 4, meaning the request had an issue (e.g., wrong data sent).
404 Not Found (the legendary "resource not found" error—everyone’s seen it).
400 Bad Request (invalid request structure—could be used for all client errors, but we categorize them).
Server Errors (5xx) – Start with 5, meaning the server failed (e.g., code crashed despite correct input).
500 Internal Server Error (the infamous "server 500"—internal server failure).
Semantics Matter
Status codes (like HTTP methods) are about semantics. Technically, nothing stops us from:
Returning a 200 OK even if an error occurred (but nobody does this).
Using a GET request to create a resource (but again, nobody does this).
It’s all about following conventions to keep APIs predictable and maintainable.
REST API application programming interface an architectural style tested by time that tells how to most efficiently communicate between client and server over HTTP how to interact with a program and this is specifically a programmatic interface suppose we have a program that we can interact with to perform the following actions get current currency rates convert one currency to another get a weekly weather forecast for this the server must provide us with some interface through which we can do this we need to send a GET request to a specific URL in the query parameters specify the date for which we need the forecast and the city for which we want to get this forecast and the server in the response body will return an array consisting of objects which contains time temperature whether it will rain and all the necessary information for us and we see that by sending a request with the appropriate parameters we get the corresponding response this is what an API is how we interact with the server
REST API architectural style is a set of rules that describes how to use HTTP and build your API so that it is convenient to use can handle loads scales easily and so on that is to extract all the benefits the first concept states that the interaction model with REST API is client-server the API is represented as a server and the consumers clients can be desktop browser mobile applications as well as other servers that communicate with our server under some contract the next concept is the multi-layered nature of the system that is in REST the system can have any number of layers and from the client's perspective this does not matter at all from the client's perspective this entire system appears as a single unified whole while inside there can be any number of layers with load balancing distribution some microservice architecture the third concept is that the server should not maintain any state stateless no state example the client sends a request the server returns some response and no intermediate state is remembered from the server's perspective that is with each subsequent request the client and server communicate as if for the first time for the server to identify the client what data to return what operation to perform the client sends all the necessary information so that the server can process and execute it this is one of the most important concepts the fourth concept is the uniform unified interface that the API has suppose we have an online store for any products we can perform CRUD operations Create Read Update Delete that is add a product delete a product update information get a list of products an array and by ID we get information about a specific product
how to interact with such operations there are HTTP methods POST DELETE PUT PATCH and GET and each of these methods has a certain semantics POST creation DELETE deletion PUT PATCH update GET retrieval that is for each CRUD operation we use an HTTP method for each entity we have a specific URL with which we interact in this case for products it is the URL /products if we want to get information about a specific product then we add an ID at the end /products/id this exact way of working with all endpoints is that very uniform unified interface we can also add here the interaction format JSON XML headers required for user authorization some kind of token and for example something like in one header there could be authorization_token x-token that is everything should be uniform and in a single logical style dictated by REST API that is the request itself must contain all the necessary information to execute it we can’t just tell the server create a product by simply sending a POST request we must provide everything necessary we need to give the server all that is required so it can create this product that is in addition to the POST request itself we specify the product information in the request body the corresponding headers the method the corresponding URL and only then can the server process this request this is semantics that is with a GET request we should retrieve data and we should not modify delete or create although in theory technically we can do this nothing prevents us from using only GET requests for everything and performing any operation through them HTTP allows this but REST semantics are precisely about the most efficient use of HTTP and we would violate them if we used GET for modifying data with PUT it’s a bit more complicated there is such a concept as request idempotency and some requests are considered idempotent while others inherently cannot be idempotence an HTTP method is considered idempotent if a repeated request made several times in a row has the same effect that is if we try to update a resource and send the same request with the same update data several times the server should execute this request the same way there shouldn’t be a situation where the first request performed one action and the second request performed different actions idempotence is a property that means that an identical request repeated several times in a row has the same effect and does not change the server’s state correctly implemented GET PUT and DELETE methods are idempotent but POST for example cannot be idempotent by nature and if we send the same POST request with the same data several times in a row the server will create several different resources for us that is the result here is partly predictable but not entirely different resources are still created the effect is not the same this is exactly why a POST request is not idempotent now with an example of a PUT request if we change the age of some resource for example a user from 10 to 20 and then send the same PUT request again trying to change the age to 20 nothing will happen the server won’t create a new resource won’t delete it it will simply update the same attribute of some entity caching and caching can be implemented via HTTP by setting certain headers or via some third-party means implemented on the server for example using Redis Memcached and so on and an important point from the semantics perspective GET and POST requests can be cached while PUT and DELETE cannot and what caching generally implies we have a server and a million clients simultaneously or at some time interval request a list of currencies via a GET request but the list of currencies changes very rarely and each time fully sending a request fully accessing the database retrieving this list of currencies to return it to the client doesn’t make much sense so we can have a cache this cache can be implemented via HTTP headers and the results of this cache will be stored right in the browser or via some third-party systems implemented on the server for example Redis for example we specified that we want to cache the result saved it somewhere in the browser now the next time our client requests the list of currencies we see that it is already in the cache and we don’t send the request to the server again but retrieve it from the cache that is it happens much faster and as a side effect reduces the load on the server you could say some command to our smart home turn on the light and your light will turn on that is a kind of optimization of your time well with caching it’s basically the same thing we don’t go to the database every time we don’t send a request every time but retrieve data that rarely changes from this cache about the data exchange format between client and server with REST you can exchange almost any data but mostly it’s JSON however XML is also used in fintech and banking XML is quite common the next important point is versioning imagine a situation where we have some set of endpoints we work with them we have some clients that use these endpoints and at some point we need to make some changes to our API but these changes are not backward compatible that is for example we want to completely remove the user deletion method or somehow change the communication format and if we do this directly in the current code in the current API version then all clients working with us will break but everyone perfectly understands that all changes we make must be backward compatible and of course when you make such changes that somehow modify the data format you need to change the version so users working with the first API version continue to work with it while new users or users who want to migrate start working with the new version the second third fourth fifth etc

API documentation again this is not specific to REST but applies to any API really but REST even has certain specifications about how your API should be documented and this is where we remember OpenAPI and Swagger OpenAPI is a specification that allows you to document your API - what endpoints you have what methods what status codes what query parameters are expected what request body what response body will be returned what errors should be handled and so on including API version basically allllllll the necessary information for us to start working with this API now about Swagger Swagger is essentially an implementation of OpenAPI its a set of tools for documenting and visualizing our REST API in most programming languages and frameworks there are tools that allow you to automatically with almost no additional effort generate documentation based on your endpoints and you can just supplement it

SOOOOOO
the interaction model in REST is client-server
the system can be multi-layered
also REST must be stateless - each time client and server communicate as if for the first time
must have a uniform standardized interface
API can be cached
data exchange format is most often JSON
API should be versioned ideally of course your API should be documented
REST is not a protocol its an architectural style a set of rules whereas SOAP is actually a protocol for exchanging structured messages and while in REST we can have any data format JSON XML or something else in SOAP its only XML and specifically SOAP XML with its own specifics that said nothing prevents you from implementing both REST and SOAP within one application one server one backend meaning your business logic is some separate core there are REST controllers that return JSON and there are SOAP controllers with described WSDL that return XML if REST is a set of rules for efficient HTTP usage then SOAP in turn can work with any application layer protocol SMTP FTP HTTP and others for describing SOAP services WSDL Web Service Description Language is used its a specific language based on XML here there are no endpoints in the classical REST sense here we have so-called operations for example we have some GET and it has INPUT which we expect and OUTPUT what will be returned theres just this WSDL language used to describe SOAP services when comparing REST is like many windows we can knock on or many doors we can open whereas SOAP is more like one window where we need to pass the procedure name the operation we want to perform SOAP unlike REST has certain strictness because REST is after all just some set of rules an architectural style while SOAP is a protocol that sets certain boundaries certain frameworks and messages sent in SOAP have a specific structure

four parts of this structure three mandatory and one optional which handles errors

Envelope the root element that defines the start and end of the message and its thanks to this that the client understands when the message is fully received
Header something like headers in a regular HTTP request it allows us to define some additional properties for the application for example send some token specify the message format type and any other auxiliary information
Body the payload where we transmit useful data some meaningful information
REST is essentially just a set of recommendations with a loose structure while SOAP on the other hand is a protocol that defines strict rules rigid structure and confines us within certain boundaries services here are described using WSDL and message exchange happens in XML format SOAP is often used in banking systems

GraphQL is a query language its neither an architectural style nor a protocol its specifically a query language imagine we have an electronics store with a product details page that requires lots of data various specifications descriptions prices basically everything about a particular product then we have another page displaying products as a list where we only need minimal data just the product model its rating and price or consider an admin panel displaying data in tables where we need more data with traditional approaches we'd either have one endpoint returning all possible data including nested fields we might not need for a specific request or create multiple backend endpoints like little data big data of course nobody actually names them this way but just for example meaning one request returns data for one page another request returns data for another page and so on but this isn't optimal we'd prefer if the client could specify exactly what data it needs in each case ideally the client would send a request for products saying give me data with just the ID name and price then the server would discard all unnecessary characteristics and return only the requested fields this is exactly what GraphQL does differently whereas traditional approaches have the server define the schema and data format for each endpoint in GraphQL the server only defines the data schema while the client requests exactly which fields and attributes it needs in one query you might request three fields from an object in another you might request all 53 fields
GraphQL has two main types of queries Query and Mutation
Query is analogous to a GET request
Mutation is analogous to a POST request
with Query we retrieve data with Mutation we either create or modify data
there's also Subscription which handles realtime data changes essentially a subscription to data updates these subscriptions work over WebSockets
first and foremost we define the data schema this is similar to regular interfaces where we just describe fields and their types after defining the schema and implementing backend logic from the frontend we can request data for example from user we might request only the name field we can also request nested data like each user's array of friends and specific nested fields only those we need we can pass Input as query arguments for instance we might specify we want a person with id=1000 and request just the name and height frequently requested fields can be organized into Fragments for reuse across different queries this avoids repetitive definitions allowing us to reuse components in various places.Mutation is essentially a regular query that mutates data changes creates something performs an action updates an entity etc for example we might have some Input specifying which fields we want in the response body we send the request and the backend returns only the requested data it works the same way request the needed data send a Mutation and the server returns what we asked for suppose we have a User with a list of posts and a separately defined Post type we describe Inputs what we expect as input all the types Queries and Mutations we specify what we expect as input and what each Query or Mutation returns for example getAllUsers returns an array of users getUser returns a specific user by id and createUser is a Mutation then we implement the endpoints and business logic like finding a user by id returning all users creating a user adding them to an array assigning an ID interacting with the database we specify the URL where everything will be available define the schema and start the server then at the specified path we get access to a sort of admin panel where we can view all queries mutations data types and conveniently this is all provided to the frontend allowing it to determine exactly what data it needs accordingly it can request only what's required in each specific situation we can also examine mutations searches whatever we need to find importantly in a single query we can request different data meaning we can make combined queries for example we might request a list of all users asking the backend for just id and username we send the query and see what the endpoint returns we could try requesting only id then try requesting some nested entity like dishes and title now the advantages GraphQL offers us:
GraphQL offers partial self-documentation thanks to its strict schema all Inputs Outputs Queries Schema types documentation - these are all partially self-documenting the schema is code-generatable again due to the strict schema we can generate code including on the frontend the workflow goes like this we describe some query for example to get a list of all todos with certain fields then we run a specific script using a specific tool and point it to the schema path after which in the basic version it will automatically generate all types for us we won't have to describe them manually and we'll have almost complete type matching between frontend and backend but this can also be further customized to generate for example endpoints for RTK Query generate queries for React Query or just queries with predefined parameters overall this is another cool feature of GraphQL the next advantage probably the main one is that the client requests only the data it needs this directly leads to less network traffic we don't request huge datasets we can request only what we need in a specific situation this affects both performance speed and client-side traffic consumption all benefits really.WebSockets are also a protocol but unlike HTTP where we establish a connection send a request get a response and terminate the connection here we maintain a persistent connection in HTTP there are exceptions of course in realtime applications for example but in the classic approach each request establishes a new connection in HTTP WebSocket is specifically a protocol for realtime interaction where client and server continuously exchange data through a persistent connection when are WebSockets needed obviously things like chats where you continuously exchange messages or stock charts where you need to show rapid changes like currency rates or stock prices that constantly update in realtime let's start with HTTP similar setup - there's a server communicating with a database we send a request get a response and the connection terminates in this case if we need broadcast functionality like sending a chat message for other users to receive this message they would need to request it meaning send another request WebSockets work differently all online users roughly speaking establish a connection with the server - a persistent connection where both client and server continuously exchange messages in this case when one user sends a message to the server the server can immediately share this message with everyone it's connected to so-called broadcasting and because we don't need to constantly establish and terminate connections client and server can exchange messages continuously in this bidirectional format there are 4 realtime chat implementations in practice using different technologies WebSockets long polling Server-Sent Events and Short Polling how WebSockets work in general for example we have a simple server basic WebSocket server we attach handlers for connection and message events and process these messages we send an event field from the client to determine which action should execute connection or message sending we can also have broadcasting where we loop through all online clients and send them messages now on the client side we establish a connection but instead of http we specify ws the protocol specify the port and connect unlike HTTP we don't specify this with each request only during connection we can have events like onOpen onMessage onClose and onError and we can handle each of these events and implement specific logic message sending connection establishment connection closing etc

About Remote Procedure Calls RPC specifically gRPC and tRPC the concept of RPC is remote procedure calls we have a client and a server the server implements some method for example client.stub.doSomething() or addToCart or some other action while this method isn't implemented on the client the client can call this method using a special object called a stub and it does this as if the method was implemented locally so this is remote procedure calling in reality it sends a network request the server sends some data but from the client's perspective it all happens as if the client itself called this procedure and performed the action this is exactly that remote interaction meaning the server implements some method from RPC perspective called a procedure and the client can call these procedures remotely while from the code perspective it looks like stub.procedureName() or methodName sounds quite convenient.Now about gRPC. gRPC is essentially a toolkit, a platform from Google (open-sourced in 2015) that implements this whole remote procedure call concept. It's super popular in microservices architecture - this is exactly how microservices talk to each other. And it comes with all the benefits of HTTP/2 and more. What makes gRPC different from traditional approaches? First, it uses HTTP/2 instead of HTTP/1.1. Tests show HTTP/2 is about 10-15% faster than HTTP/1.1. Instead of text-based messages used in HTTP/1.1, HTTP/2 uses binary format which allows for better compression, processing and faster transmission. HTTP/2 also implements data streaming - simple and lightning fast. Instead of JSON which is verbose and doesn't compress well, gRPC uses a binary format called Protocol Buffers (protobuf). Plus gRPC comes with out-of-the-box tooling: code generation for multiple programming languages which makes it more flexible and versatile. The built-in tooling includes authentication, data streaming (including bidirectional) and much more. And of course the whole remote procedure call approach allows us to conveniently invoke these procedures - the client calls them as if they were implemented locally.

Now let's look at the data exchange format - protobuf. It's a simple binary format that compresses really efficiently unlike JSON. It's strictly typed unlike JSON where you can send a string in one case and a number in another for the same field - no such ambiguity here. Though data needs to be serialized into protobuf before sending and deserialized on the client side. But since we don't have JSON's verbosity and inefficient compression, we get massive performance gains. After writing the proto file, we run it through a compiler and get generated code for multiple languages - very convenient for microservices and development in general.

Finally let's look at tRPC - a relatively new tool. tRPC stands for TypeScript Remote Procedure Call. The idea is to seamlessly connect server functions to the client without writing formal endpoints or messing with axios/fetch, and especially without duplicating type definitions. You just write a function on the server and tRPC automatically makes it callable directly from the client with full TypeScript type checking. Pass wrong arguments? TypeScript will immediately flag it. It works using routers and procedures (queries and mutations, similar to GraphQL but without its complexity). A router groups related functions together like userRouter or postRouter, while a procedure is the actual callable function. For example you'd write:

const appRouter = createRouter({
getUser: publicProcedure
.input(z.object({ id: z.string() }))
.query(({ input }) => {
return getUserFromDatabase(input.id);
}),
});

And then call it from the client like this:

const user = await api.getUser.query({ id: "123" });

No fetching, no manual parsing, no fear of mismatched types - everything is typed and autocompleted. Super convenient for large projects where you want consistency and protection against simple typos. tRPC works great when your frontend and backend are both in TypeScript, like in a Next.js project. But if your server is in Python, Go or something else - not gonna work. It's not a protocol or language - just a library that makes life easier when client and server are in the same codebase sharing types. Everything just works seamlessly, especially if you're already using TypeScript and want your client and server to speak the same language - then tRPC is exactly what you need.
 
\\\\\\\\\\\\\\\\\\\\\\\\\
RUS
\\\\\\\\\\\\\\\\\\\\\\\\\

Что такое Rest API (http)? Мыло? ГрафQL? Вебсокеты? РПК (гРПК, тРПК). Клиент - сервер. Вся теория Но почему я HTTP-протокол изменился с архитектурными стилями (REST, SOAP) или же, с GraphQL с запросами запросов? По сути, это вообще разное. Все это зависит от того, что клиент-серверная архитектура определяет способ общения клиента и сервера. Про клиент-серверную архитектуру: В такой архитектуре сервера все вычислительные системы хранения данных, какая-то бизнес-логика, клиенты с этим сервером могут взаимодействовать. то есть железная машина, на которой крутится наше серверное приложение, которое взаимодействует с базой данных, определяет протоколы взаимодействия, определяет API, и клиент во всей архитектуре с какими-то определенными действиями может с помощью сервера общаться: может возникнуть проблема с какими-то данными у него, и сервер ему эти данные вернет. И всё это работает в формате "запрос-ответ", то есть данные клиента запрошены - сервер эти данные вернул. И здесь не только про данные, мы также можем дать серверу возможность выполнить выборку какого-либо действия, например, зарегистрировать нового пользователя или провести оплату или добавить товар в корзину. И каждый сервер уже определил, может ли он выбрать это действие или не может, и в зависимости от этого он будет возвращать разный ответ, то есть сервер будет воспроизводиться как единое доказательство вычисления. В самом начале ошибочно предполагалось, что клиент - это может быть какой-то браузер. Но это и мобильное приложение, и другой сервер, который обращается к этому серверу, то есть любой и абсолютно любой контакт извне.даже если мы сказали: «Все умному включите домашний чайник», то это уже самое то. То есть сама аббревиатура «клиент-сервер» означает, что сервер — это поставщик каких-то данных, услуг, логики, клиент — он потребляет эти данные. А для клиентов сервер - это такое единое, цельное, какое-то монолитное приложение, источник данных. Но при этом сам сервер под капотом может быть большим, распределенным, состоящим из нескольких микросервисов, но при этом клиенте это особенно не волнует и не должно. Про то, на чём в принципе основан весь веб- это HTTP. HTTP - это гипертекстовый транспортный протокол, который находится на самом верхнем уровне модели OSI, модели TCP/IP - это уровень приложений. Именно с помощью HTTP общаются большинство приложений в Интернете. Первоначальная идея HTTP - это обмен гипертекстовыми документами, то есть с нашими HTML-ками, но сейчас с помощью HTTP-сети можно использовать практически любые данные: текстовые, файлы, HTML, XML, JSON - в общем, практически в любом формате. По сути HTTP-пример запроса. Если разобить HTTP-запрос на составные части и посмотреть структуру, то первая строка HTTP-запроса - это начальная строка, и она состоит из трех частей: Метод URL Версия HTTP ! ! !
POST/вход HTTP/1.0

Метод - это, грубо говоря, семантический запрос, то есть то, что мы хотим конкретно сделать, мы хотим создать какой-то ресурс, обновить его или получить. В данном случае POST говорит о том, что мы хотим какой-то ресурс создать или просто сделать что-то. URL - это то, куда мы отправили запрос. В данном случае мы отправили его на /login-то есть сервер, который понимает, какое именно действие мы хотим совершить. Ну и далее переходим к версии HTTP.

Следующая часть структуры HTTP — это заголовки (headers).заголовки содержат достаточно всю информацию. В них есть часть заголовков обязательных и часть заголовков необязательных. так же можно приготовить какие-то свои кастомные заголовки. Host:example.com Content-Type:application/x-www-form-urlencoded;charset=utf-8 Content-Length:26 В них преобразуется информация о хосте, с которого был отправлен запрос, информация о браузере или тип устройства, с которого отправляется запрос, тип контента (text/html или какой-то другой тип), а также могут передаваться различные авторизационные заголовки с токенами, а также обеспечивать безопасность взаимодействия различных источников сети (CORS) - заголовки, обеспечивающие безопасность источников общения, расположенных в разных доменах). Третья часть HTTP-запроса, любой HTTP-запрос — это само сообщение, то есть в нем клиент отправляет серверу какие-то данные, которые ему нужны, в wt мы отправляем, например, логин пользователя и пароль для того, чтобы сервер мог распознать этого пользователя, то есть клиент отправляет запрос, который выглядит так: { login=user пароль=qwerty } , и сервер должен вернуть ему ответ. Ответ немного отличается от запроса HTTP/1.1 200 OK Content-Type:application/json Соединение:Закрыто {сообщение:'успешный вход в систему', пользователь: {id:'1', имя пользователя....} }

стартовая строка выглядит немного иначе, дело в том, что в ответе стартовая строка называется «строка следствия», она содержит версию HTTP, такой статус-код, который определяет, успешно ли был выполнен запрос. Также в ответе такие же заголовки заголовков, но они выделяются из тех, которые были в запросе, есть заголовки запроса и есть заголовки ответа, и точно так же есть телесные сообщения, в которых сервер получает клиентские данные. (индивидуальный товар). POST-передача данных(создание ресурса)(например, auth/login) PUT-обновление ресурса(PUT и PATCH приводят к обновлению ресурса, но они тоже разные, PUT обновляет ресурсный процессор, PATCH как правило обновляет только часть ресурса) PATCH- обновление фрагмента ресурса частично DELETE- удаление ресурса(удалить пользователя,товар) строки запроса, которая извлекает сервер уже в виде ответа. Здесь самой важной частью является статус-код, который сообщает о том, что именно в этом запросе есть пять групп этих статус-кодов: информационные (1xx) — они всегда начинаются с единички (например, 100, 101, 102 и ......). Успешные (2xx) — коды статуса, начинаются с двойки, обозначают, что запрос завершился успешно. Редиректы (3xx) начинаются с тройки, обычно означают какой-то редирект или перенаправление, например, мы успешно залогинились и нас перенаправляет на другую страницу. Ошибки клиента (4xx) — начинают корректироваться с четвёрки, обозначают, что запрос был обработан с ошибкой (например, клиент передал неправильные данные).404 (легендарный статус-код, который говорит о том, что какой-то ресурс не найден) появился все.тот самый легендарный 404 Not Found — когда мы не нашли ресурс, 400 Bad Request — статус-код чаще всего говорит, что запрос был не таким (опять же есть это же всё про семантику) - ничего нам не мешает всегда 400-й статус-код на все клиентские ошибки, (но мы их разделяем) Ошибки сервера (5xx):Ошибка сервера (Ошибка сервера) — начинаются с пятёрки — этого сервера (например, клиент передал ошибки все корректные, но на уровне написали неправильный код, там что-то сломалось, и сервер ответственно назначает 500-й статус-код). Это еще называют "сервер пятисот ставить".500 Internal Ошибка сервера — о том, что это внутренняя ошибка сервера. ну и опять же, статус-коды — это про семантику, то есть ничего не мешает нам, в окне выбора действия с ошибкой, но вернуть какой-то 200-й статус-код. Но так как я понимаю, обычно никто этого не делает. То же самое и с методами — ничего не мешает сделать так,чтобы GET-запрос создать какой-то ресурс, а не вернуть какие-то данные, но опять же так никто не делает. 201 Created-говорит об успехе, что ресурс был успешно создан,

REST API — архитектурный стиль интерфейса прикладного программирования, проверенный временем, в котором сообщается о том, как наиболее эффективно обмениваться данными с клиентом и сервером по HTTP, как с программой общаться стоит. Предположим, у нас есть программа, обратившись к которой, мы можем выполнить следующие действия: Получить актуальный курс валюты, переконвертировать одну валюту в другую, получить прогноз погоды на неделю. Для этого сервера мы должны указать какой-то интерфейс, с помощью которого мы можем это сделать. Сервер в качестве тела ответа возвращается в виде массива, состоящего из объектов, в котором есть время, температура, будет дождь и вся необходимая для нас информация. Если мы видим, что отправленный запрос соответствует параметрам, мы даем соответствующий ответ. Это и есть API-интерфейс, как мы взаимодействуем с сервером.

REST API: архитектурный стиль — это набор правил, который описывает, как использовать HTTP и построить свой API так, чтобы ей было удобно пользоваться, чтобы она выдерживала нагрузку, легко масштабировалась и так далее. То есть, чтобы мы извлекли все плюсы. Первая концепция говорит о том, что модель взаимодействия с REST API — это клиент-сервер. API, предоставляемый в виде сервера, пользователями (клиентами) могут быть как настольными, браузерными, мобильными приложениями, так и другими серверами, которые по какому-то контракту общаются с нашим сервером. Следующая концепция – многоуровневость или многослойность системы. То есть по REST система может иметь n-ное количество слоёв, причём с точками зрения клиента это вообще никакие роли не играет. Третья концепция заключается в том, что сервер не должен определять какое-либо состояние (без сохранения состояния (отсутствие состояния)). Пример: клиент отправляет запрос, сервер возвращает ему какой-то ответ, и при этом никакое промежуточное состояние не запоминается (с точки зрения сервера). То есть при каждом следующем запросе клиент и сервер общаются, как бы в первый раз. Для того, чтобы идентифицировать сервер, какие данные возвращаются в ходе операции, клиент отправляет всю необходимую информацию для того, чтобы сервер смог его обработать и восстановить. Четвёртая концепция-это единообразный(унифицированный) интерфейс, которым владеет API.у нас в интернет-магазине. Над любыми товарами мы можем выполнить CRUD-операции (Создать, Чтение, Обновление, Удаление), то есть добавить товар,удалить товар,обновить информацию,получить список товаров(массив) и по ID получить информацию именно по конкретному продукту Как с такими операциями взаимодействовать? есть HTTP-методы POST, DELETE, PUT, PATCH и GET и каждый из этих методов имеет определенную семантику POST-создание,DELETE-удаление,PUT/PATCH-обновление,GET-получение. То есть для каждой CRUD-операции мы используем HTTP-метод, для каждого экземпляра у нас есть определенный URL, по которому мы с ней взаимодействуем. В данном случае для товара это URL---- /products Если мы хотим получить информацию по конкретному товару, то в конце у нас включится ещё ID------ /products/{id}. Вот именно такая работа со всеми endpoint'ами и есть тот самый единообразный, унифицированный интерфейс. Сюда же можно добавить еще формат взаимодействия (JSON, XML), заголовки, которые необходимы для авторизации пользователя (какой-нибудь токен). И например, такого типа, что в одной заголовке может быть авторизация_токен,х-токен, то есть все должно быть единообразным и в одном едином логическом стиле, который диктует REST API, чтобы есть сам запрос, должен сохранять все, что нужно по информации для его выбора. Мы не можем просто взять и сказать серверу "создай товар",просто отправив POST-запрос. Мы должны предоставить все необходимое, нам нужно дать серверу все, что требуется, чтобы он смог создать этот товар. Помимо самого POST-запроса, мы указываем информацию о товаре в теле запроса, соответствующие заголовки, метод, соответствующий URL-адрес, и только тогда сервер может обработать этот запрос - эту семантику, то есть, с помощью GET-запроса мы должны получать данные, а изменение, удаление или создание мы не должны. Хотя в теории, чисто технологично мы можем так сделать - ничего не мешает нам вообще использовать все GET-запросы и любую операцию делать через них, HTTP это позволяет, но семантика REST - это как раз про наиболее эффективное использование HTTP и мы нарушим, если будем использовать GET для изменения данных. в PUT всё немного сложнее. Есть такое понятие, как идемпотентность запроса. Причём какие-то запросы к идемпотентным, а какие-то априори не могут быть такими. Идемпотентность, метод HTTP-считается идемпотентным, если повторный запрос, сделанный несколько раз подряд, имеет один и тот же эффект. То есть, если мы пытаемся обновить ресурс и отправляем один и тот же запрос с одинаковыми данными при обновлении, то сервер должен выбрать этот тип запроса, который не должен быть таким, что первый запрос сделал одни действия, второй запрос сделал другие действия. Но вот POST, например, идемпотентным по своей природе быть не может, и если мы отправим POST-запрос совпадают с несколькими данными при подряде, сервер создаст у нас несколько разных ресурсов. То есть результат здесь уже отчасти недорогой, но не совсем ресурсы всё равно достигают разных результатов, эффект происходит не один и тот же. Именно поэтому POST-запрос не идемпотентен.теперь на примере PUT-запроса. Если мы изменим возраст в каком-то ресурсе (например,юзера) с 10 на 20, а потом ещё отправим такой же PUT-запрос с попыткой заменить возраст на 20, у нас ничего не произойдёт,сервер не создаст новый ресурс, не удалит его-он просто обновит тот самый атрибут в каком-то веществе. Кэширование. При этом кэширование может осуществляться средствами HTTP (за счет проставления определенных заголовков), а также средствами, какими бы то ни было внешними, реализованными на сервере (использование, например, Redis, Memcached и т. д.). В критический момент с точки зрения семантики точек зрения: GET и POST-запросы могут кэшироваться, PUT и DELETE-не могут и вообще кэширование условий. особого не имеет. Поэтому мы можем иметь кэш.Этот кэш может быть реализован с помощью HTTP-заголовков, и результаты этого кэша будут храниться непосредственно в браузере, либо с помощью каких-то системных компонентов, реализованных на пространстве (например, Redis), в примере, который мы определили, что мы хотим получить результат кэширования, который определяет, где его в браузере, теперь в следующий раз, когда наш клиент запрашивает валюту в списке, мы видим, что он у нас уже находится в кэше, и не отправляем запрос на повторный сервер, а доставляем из кэша. происходит гораздо быстрее, и как побочный эффект - снижает нагрузку на сервер. Можно сказать там какую-то команду для нашего умного дома - "включается свет", и свет у вас включается, то есть такого рода оптимизация вашего времени. Вот с кэшом в принципе то же самое - мы не ходим каждый раз в базы данных, не отправляем каждый раз запрос, а достаём данные, которые редко изменяются, из этого кэша. для обмена данными между клиентом и сервером. по REST можно получить практически любые данные, но в большинстве случаев это JSON. Но также встречается и используется и XML. В финтехе, банковской сфере XML достаточно распространён. Следующий момент - это версионирование, предложим ситуацию, что у нас есть какой-то набор эндпоинтов, мы с ним работаем. У нас есть какие-то клиенты, которые используют эндпоинты, и в какой-то момент нам необходимо перенести какие-то права в наш API, но эти правки не обратно совместимы. То есть, например, мы вообще хотим удалить метод удаления пользователя или как-то изменить формат общения, и если сделать это прямо в современном коде, в текущей версии API, то у всех клиентов, которые с нами работают, все сломается. Но все прекрасно понимают, что все правки, которые мы вносим, должны быть обратно совместимыми. И конечно, когда вы вносите вот такие вот правки, которые как-то меняют формат данных, надо изменить эту версию, пользователи, которые работают с API первой категории, они так и продолжают с ней работать, а новые пользователи или пользователи, которые хотят сделать миграцию, начинают работать с новой версией - второй, второй, четвёртой, пятой и тд.по REST можно получить практически любые данные, но в большинстве случаев это JSON. Но также встречается и используется и XML. В финтехе, банковской сфере XML достаточно распространён. Следующий момент - это версионирование, предложим ситуацию, что у нас есть какой-то набор эндпоинтов, мы с ним работаем. У нас есть какие-то клиенты, которые используют эндпоинты, и в какой-то момент нам необходимо перенести какие-то права в наш API, но эти правки не обратно совместимы. То есть, например, мы вообще хотим удалить метод удаления пользователя или как-то изменить формат общения, и если сделать это прямо в современном коде, в текущей версии API, то у всех клиентов, которые с нами работают, все сломается. Но все прекрасно понимают, что все правки, которые мы вносим, должны быть обратно совместимыми. И конечно, когда вы вносите вот такие вот правки, которые как-то меняют формат данных, надо изменить эту версию, пользователи, которые работают с API первой области, они так и продолжают с ней работать, а новые пользователи или пользователи, которые хотят сделать миграцию, начинают работать с новой версией - второй, второй, четвёртой, пятой и тд.по REST можно получить практически любые данные, но в большинстве случаев это JSON. Но также встречается и используется и XML. В финтехе, банковской сфере XML достаточно распространён. Следующий момент - это версионирование, предложим ситуацию, что у нас есть какой-то набор эндпоинтов, мы с ним работаем. У нас есть какие-то клиенты, которые используют эндпоинты, и в какой-то момент нам необходимо перенести какие-то права в наш API, но эти правки не обратно совместимы. То есть, например, мы вообще хотим удалить метод удаления пользователя или как-то изменить формат общения, и если сделать это прямо в современном коде, в текущей версии API, то у всех клиентов, которые с нами работают, все сломается. Но все прекрасно понимают, что все правки, которые мы вносим, должны быть обратно совместимыми. И конечно, когда вы вносите вот такие вот правки, которые как-то меняют формат данных, надо изменить эту версию, пользователи, которые работают с API первой категории, они так и продолжают с ней работать, а новые пользователи или пользователи, которые хотят сделать миграцию, начинают работать с новой версией - второй, второй, четвёртой, пятой и тд.

Документация вашего API. Но в REST есть даже определенные критерии, поэтому стоит документировать и описывать ваш API, и здесь упоминаем про OpenAPI — это спецификация и Swagger. OpenAPI - это спецификация, которая позволяет задавать документацию API, какие у вас есть конечные точки, какие методы, какие статус-коды, какие параметры запроса ограничиваются на входе, какое тело запроса, какое тело ответа будет возвращено, какие ошибки мы должны найти и так далее, версия API в том числе. В общем, всю-всю-всюююююю необходима информация для того, чтобы мы с этим API смогли начать работать. Про Сваггера. Swagger, по сути, это реализация OpenAPI, это такой себе набор инструментов для документации и визуализации нашего REST API. СОУУУУУ...... модель взаимодействия по REST - это клиент-сервер. Система может быть многоуровневой или многослойной. Также REST не должен определять какой-то статус-каждый раз, когда клиент и сервер общаются, как в первый раз. Должность является единообразным унифицированным интерфейсом. Также API может кэшироваться. Формат обмена данными меняется всего на JSON. API должен быть версионирован, в идеале конечно, ваш API должен быть задокументирован. REST - это не протокол, это архитектурный стиль, набор правил, а в свою очередь, SOAP - это уже протокол обмена структурированными сообщениями, и если в REST у нас может быть любой формат данных - JSON, XML либо какой-то ещё, то в SOAP это только XML и XML только -SOAP XML со своей спецификой. При этом никто не запрещает вам в рамках одного приложения, в рамках одного сервера, реализовать один бэкенд и REST и SOAP. Для того, чтобы у вас была бизнес-логика-это-то отдельные ядра, есть REST-контроллеры, которые возвращают JSON, есть SOAP-контроллеры, в описании которых WSDL и которые возвращают XML. Если REST — это набор правил для эффективного использования HTTP, то SOAP, в свою очередь, может использоваться с любым протоколом прикладного уровня: SMTP, FTP, HTTP и другими. Для описания SOAP-сервисов используется WSDL (язык описания веб-сервисов) - это определенный язык, основанный на XML. Здесь нет эндпоинтов в классическом определении, как в REST, здесь есть такие вызовы операций. Например, у нас есть какой то GET и у него есть INPUT, который мы ожидаем на входе и OUTPUT, что будет выдано на выходе. Просто есть такой зык WSDL и с помощью него определяются SOAP-сервисы. REST при рассмотрении этого количества окошек, которые мы можем разместить, или множества дверей, которые мы можем открыть. В свою очередь, SOAP — это, скорее, одно окно, в котором нам необходимо передать название процедуры, название операции, которое мы хотим выбрать. SOAP в отличие от REST обладает определённой строгостью,потому что REST- это всё-таки какой-то набор правил, архитектурный стиль SOAP - это уже протокол, который задаёт определённые рамки, определённые границы. Сообщения, которые отправляются в SOAP, обладают определенной структурой. Четыре части этой структуры: три обязательных и одна опциональная (она несет ответственность за ошибки).

Конверт - это корневой элемент, определяющий начало и конец сообщения, и именно благодаря ему клиент понял, что сообщение получено полностью. Заголовок - это что-то вроде заголовков в обычном HTTP-запросе, он дает нам возможность определить какие-то дополнительные свойства для приложения, например, отправить какой-то токен, указать тип формы сообщения и любую другую вспомогательную информацию. Тело(тело)-в которое мы передаем уже какую-то полезную нагрузку,какие-то полезные данные.

REST — это просто набор рекомендаций в своей основе с независимой структурой, а SOAP, в свою очередь, — это уже протокол, который устанавливает строгие правила, строгую структуру и загоняет нас в определенные границы. Здесь о предоставлении услуг с помощью WSDL и обмена сообщениями всегда в формате XML. Часто SOAP используется в банковской сфере.

GraphQL - язык запросов.GraphQL - это уже не архитектурный стиль и не протокол, это языковые запросы, например, у нас в магазине электроники и здесь есть страница детального просмотра информации по конкретному коду, здесь запрашивается много данных: всякие характеристики, описания, стоимость в целом много-много всего по конкретному параметру, также у нас есть другие страницы, где мы отображаем товары уже на списком, и нам здесь необходимо запросить мало данных. Чтобы нам достаточно отобразить модель товара, его рейтинг и стоимость. или, например какая-нибудь админка, где нам нужно отобразить данные в виде таблицы, например какой-нибудь для админов. И там нам нужно уже больше данных, иииии вот, при классическом подходе нам пришлось бы сделать следующее: либо у нас была бы одна конечная точка, которая возвращала бы массив абсолютно всех данных, которые нам нужны, то есть объект со всеми вложенными полями, которые нам даже могут быть в конкретном запросе не нужны, либо же мы на сервере должны были бы делать разные конечные точки, такие как «Маленькие данные», «Большие данные» (конечно, никто не считает, это просто для примера), чтобы есть в одном мы возвращаем нужные данные для одного, в другом запросе - нужные данные для страниц страниц, для четвёртой и тд, но это не учитывает подход, возможно, и имел бы возможность, клиент сам предоставляет, какие данные ему в конкретных нужных, схематически мы хотим иметь какое-то такое изображение: клиент отправляет запрос на изображение продукта, для товаров и говорит: "Дай мне данные с идентификатором, именем и стоимостью", и на стороне все лишние данные, характеристики отправляются, и возвращаются товары страницы только с теми полями, которые запрос мыили. И вот GraphQL как раз для этого и предназначен, если при классическом подходе сервер определяет схему и формат данных, которые передаются в конкретном конечном пункте, то в GraphQL сервере как раз определяется только схема данных, а клиент уже сам запрашивает мне данные, поля и характеристики, атрибуты, которые ему требуются. В одном запросе нужны три поля из запрашиваемого объекта. В другом нужно 53-значит, можно запросить все 53 поля. В GraphQL есть два основных вида запроса: это Query и Mutation. Query-это аналог GET-запроса. Мутация - это аналог ПОСТ-запроса. То есть с помощью Query мы какие-то данные получаем, с помощью Mutation либо создаём, либо меняем. Также есть ещё подписка — это какие-то изменения в реальном времени, своего рода подписка на изменение данных. Подписки покрытия поверхности WebSockets В первую очередь ---- опишите схему данных. В принципе, это выглядит на обычных интерфейсах, где просто важны поля и типы полей. После того, как мы описали схему, сли какую-то логику на сервере бэкенде, с фронта мы можем запросить данные, например, у пользователя, мы запрашиваем только одно имя поля, также мы можем запросить какие-то вложенные данные, например, у каждого пользователя есть массив друзей, а также вложенные какие-то поля - только те, которые нам нужны, мы запросим.При входе в запрос можно передать какой-то входной аргумент, например, мы можем указать, что мы хотим получить человека с id= 1000 и хотим запросить имя и рост при этом, какие-то часто запрашиваемые поля, мы можем вынести в такие вызовы фрагменты и использовать их в разных запросах. То есть это сделано для того,чтобы мы могли какую-то часть не описывать каждый раз заново,а переиспользовать в одном месте, в другом месте ну иииии ...... Мутация-это по сути тоже обычный запрос, но который как-то данные мутирует: конфигурирует, создаёт что-то, выполняет какое-то действие, обновляет какое-то существо и так далее. и бекенд-нам получает только нужные данные. По сути, это работает точно так же: запрашиваем нужные данные, отправляем мутацию, а сервер возвращает нужные данные. Допустим, есть у нас пользователь, у которого есть список каких-то постов, есть отдельно описанный тип Post.описывающих входных данных - это то, что мы ожидаем на входе, что является следствием соответствующих всех типов, следствием запросов, следствием мутаций. То есть getAllUsers возвращает массив пользователей, getUser возвращает по идентификатору конкретного пользователя, и мутация createUser.Далее о результатах сами эндпоинты, бизнес-логика какая-то,то есть мы, например, по id пользователя находим, возвращаем всех пользователей, создателем пользователя, подставляем его в массив, присваиваем какой-то идентификатор, с базой данных взаимодействуем. Потом указываем URL, по этому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому пути, который мы определили, что нам будет доступен тип админки, то есть мы можем просмотреть все запросы, все изменения, просмотреть какой тип у нас данных и что удобно - это всё отдается фронту, и фронт сам определяет, какие данные нужны ему. Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. При этом мы также можем написать какой-то запрос и, что важно, в одном запросе мы можем запросить разные данные, то есть мы можем сделать комбинированные запросы. к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем видеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:чтобы мы могли какие-то части не описывать каждый раз заново, переиспользовать в одном месте, в другом месте ну иииии ...... Мутация-это по сути тоже обычный запрос, но который как-то данные мутирует: конфигурирует, создаёт что-то, выполняет какое-то действие, формирует какое-то вещество и так далее. только нужные данные. По сути, это работает примерно так же: запрашиваем нужные данные, отправляем мутацию, а сервер возвращает нужные данные. Допустим, есть у нас пользователь, у которого есть список каких-то постов, есть отдельно описанный тип Post.описывающих входных данных - это то, что мы ожидаем на входе, что является следствием соответствующих всех типов, следствием запросов, следствием мутаций. То есть getAllUsers возвращает массив пользователей, getUser возвращает по идентификатору конкретного пользователя, и мутация createUser.Далее о результатах сами эндпоинты, бизнес-логика какая-то,то есть мы, например, по id пользователя находим, возвращаем всех пользователей, создателем пользователя, подставляем его в массив, присваиваем какой-то идентификатор, с базой данных взаимодействуем. Потом указываем URL, по этому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому пути, который мы определили, что нам будет доступен тип админки, то есть мы можем просмотреть все запросы, все изменения, просмотреть какой тип у нас данных и что удобно - это все отдается фронту, и фронт сам определяет, какие данные нужны ему. Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. При этом мы также можем написать какой-то запрос и, что важно, в одном запросе мы можем запросить разные данные, то есть мы можем сделать комбинированные запросы. к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем увидеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:чтобы мы могли какую-то часть не описывать каждый раз заново, переиспользовать в одном месте, в другом месте ну иииии ...... Мутация-это по сути тоже обычный запрос, но который как-то данные мутирует: конфигурирует, создаёт что-то, выполняет какое-то действие, формирует какое-то вещество и так далее. только нужные данные. По сути, это работает точно так же: запрашиваем нужные данные, отправляем мутацию, а сервер возвращает нужные данные. Допустим, есть у нас пользователь, у которого есть список каких-то постов, есть отдельно описанный тип Post.описывающих входных данных - это то, что мы ожидаем на входе, что является следствием соответствующих всех типов, следствием запросов, следствием мутаций. То есть getAllUsers возвращает массив пользователей, getUser возвращает по идентификатору конкретного пользователя, и мутация createUser.Далее о результатах сами эндпоинты, бизнес-логика какая-то,то есть мы, например, по id пользователя находим, возвращаем всех пользователей, создателем пользователя, подставляем его в массив, присваиваем какой-то идентификатор, с базой данных взаимодействуем. Потом указываем URL, по этому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому пути, который мы определили, что нам будет доступен тип админки, то есть мы можем просмотреть все запросы, все изменения, просмотреть какой тип у нас данных и что удобно - это всё отдается фронту, и фронт сам определяет, какие данные нужны ему. Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. При этом мы также можем написать какой-то запрос и, что важно, в одном запросе мы можем запросить разные данные, то есть мы можем сделать комбинированные запросы. к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем видеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:отдельно есть тип описания пост.описывания входных данных — это то, что мы ожидаем на входе, о результате каждого типа, о результате запросов, о результате мутации. То есть getAllUsers возвращает массив пользователей, getUser возвращает по идентификатору конкретного пользователя, и мутация createUser.Далее о результатах сами эндпоинты, бизнес-логика какая-то,то есть мы, например, по id пользователя находим, возвращаем всех пользователей, создателем пользователя, подставляем его в массив, присваиваем какой-то идентификатор, с базой данных взаимодействуем. Потом указываем URL, по этому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому пути, который мы определили, что нам будет доступен тип админки, то есть мы можем просмотреть все запросы, все изменения, просмотреть какой тип у нас данных и что удобно - это всё отдается фронту, и фронт сам определяет, какие данные нужны ему. Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. При этом мы также можем написать какой-то запрос и, что важно, в одном запросе мы можем запросить разные данные, то есть мы можем сделать комбинированные запросы. к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем видеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:отдельно есть тип описания пост.описывания входных данных — это то, что мы ожидаем на входе, о результате каждого типа, о результате запросов, о результате мутации. То есть getAllUsers возвращает массив пользователей, getUser возвращает по идентификатору конкретного пользователя, и мутация createUser.Далее о результатах сами эндпоинты, бизнес-логика какая-то,то есть мы, например, по id пользователя находим, возвращаем всех пользователей, создателем пользователя, подставляем его в массив, присваиваем какой-то идентификатор, с базой данных взаимодействуем. Потом указываем URL, по этому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому пути, который мы определили, что нам будет доступен тип админки, то есть мы можем просмотреть все запросы, все изменения, просмотреть какой тип у нас данных и что удобно - это все отдается фронту, и фронт сам определяет, какие данные нужны ему. Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. При этом мы также можем написать какой-то запрос и, что важно, в одном запросе мы можем запросить разные данные, то есть мы можем сделать комбинированные запросы. к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем видеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем видеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:к примеру, указываем запрос для получения списка всех пользователей, и мы хотим из бэкенда получить идентификатор, имя пользователя, отослать запрос, и мы можем увидеть, что мы вернули конечную точку, мы можем попробовать запросить только идентификатор, попробуем запросить ещё какую-нибудь вложенную сущность, например блюда и заголовок. А теперь преимущества, которые GraphQL нам обеспечивает:

Это частичная самодокументируемость по счету по строгой схеме.

Все входы,выходы,запросы,схемы,типы,документации - это все типы - это всё частично самодокументируется. Схема - это кодогенерируемая. Опять же за счет строгой схемы мы можем ограничиться тем количеством и на коде фронтенде. Флоу работы здесь следующая: мы описываем какой-то запрос, например, получаем все todo-шек с такими-то полем, далее запускаем определенный скрипт с помощью определенного инструмента и указываем путь к схемам, после чего, во-первых, в базовом варианте мы генерируем автоматически все критерии. Нам не придется описывать их вручную, и у нас будет практически полное соответствие типов на фронтенде и на бэкенде. Но также это дело всё можно ещё по-настроить и сгенерировать, например, endpoint-ы для RTK Query, округлить запрос для React Query В или просто запросить с заданным набором параметров, в общем, это тоже достаточно классная фича GraphQL. Следующее преимущество - это, наверное, самое важное - это то, что клиент запрашивает только нужные ему данные. Из-за этого вытекает как раз то,что меньше трафика гоняется по сети. Мы не запрашиваем огромный набор данных, мы можем запросить только то, что нам нужно в конкретной ситуации. Это влияет на скорость работы и трафик, потребляемый клиентом. В общем, сплошные плюсы.

Вебсокеты - это также протокол, но в отличие от http, по которому мы устанавливаем связь, отправляем какой-то запрос, получаем ответ и обрываем связь, чтобы здесь настраиваемое постоянное соединение. Websocket — это протокол для взаимодействия в реальном времени, когда клиент и сервер за счёт постоянных соединений обеспечивают непрерывность любых данных. Когда нужны вебсокеты? Это, конечно же, какие-нибудь чаты, где вы продолжаете формировать сообщения, это графики, где нужно быстро показывать изменения, например, там, где курсы валют или на бирже, когда цены на акции постоянно меняются в реальном времени. Начну с HTTP: аналогичная схема-есть сервер, который с базой данных общается, мы отправили запрос, получаем ответ, и на этом соединении обрывается. Сервером — это непрерывное соединение, в котором и клиент, сервер постоянно передаёт любые сообщения. И уже в данном случае, если один пользователь отправляет сообщение на сервер, на сервер со всеми, с кем у него установлено подключение, он может сразу этим сообщением поделиться (так называемая широковещательная рассылка). Кроме того, нам не нужно постоянно сохранять соединение и обрывать это соединение, клиент с сервером может в таком непрерывном формате формировать сообщения вот в таком двустороннем формате. И есть 4 чата в реальном времени на основе разных технологий: это WebSocket(вебсокеты), это длинный опрос и события, отправленные сервером, короткий опрос. Как вебсокеты вообще работают. Например, у нас есть простой сервер: простейший веб-сокет-сервер, вешаем обработчик подключения и сообщения (это события), и эти сообщения мы как-то обрабатываем. Отправляемое с клиентского поля событие, которое мы определили, какое действие должно быть выбрано: подключение или же отправка сообщения. Также у нас может быть широковещательная рассылка, где мы по всем онлайн-клиентам можем пройтись в цикле и отправить им сообщение. Теперь на клиенте: устанавливаем соединение (но вместо http указываем ws-это протокол), вызываем порт и подключаемся. Только в отличие от http мы не на каждом запросе это указываем, только при подключении. И также у нас могут быть события onOpen, onMessage, onClose и onError и каждое из этих событий мы можем обработать и написать по какой-то логике: отправка сообщений, установка подключения, закрытие подключения. Об удаленных процедурах вызова (RPC), в частности о gRPC и tRPC. Понятие RPC-это удаленный вызов процедуры, у нас есть клиент и есть сервер. Сервер реализует какой-то метод, например, client.stub.doSomething() или "добавить в корзину" или ещё какое-то действие. При этом на клиенте этот метод не реализован, но клиент с специальным объектом (так называемый стаба) может вызвать этот метод, и при этом он делает так, как если бы этот метод реализован у него. Какой-то метод реализуется (с точки зрения RPC, это называется процедура), и клиент эти процедуры может удаленно вызвать. При этом с точки зрения его код выглядит как stub.названиеПроцедуры() или метод.озвучивает достаточно удобно.TODO:

Про gRPC. gRPC - это как раз набор инструментов, платформа от Google (Исходный код открыт в 2015 году), и внутри себя она использует как раз вот требование удаленного вызова этих процедур. gRPC очень популярен в микросервисной архитектуре, и вот именно микросервисы друг с другом по gRPC общаются. Учитывайте преимущества HTTP2 и другие преимущества. Что отличает gRPC от классического подхода. Во-первых, здесь используется HTTP2 вместо HTTP 1/1. HTTP2 по тестам быстрее на 10-15%, чем HTTP1/1. Вместо текстовых сообщений, которые использовались в HTTP1/1, в HTTP2 используется бинарный формат, за счет этого его можно лучше сжать, лучше обработать, отправить быстрее. В HTTP2 также реализован поток данных(стриминг), он простой и супербыстрый. Также здесь вместо JSON, который достаточно использующийся и не сжимается, используется бинарный формат, который называется protobuf, а также в gRPC есть инструментарий из коробки: это генерация кода для многих языков программирования. программирования. Это тоже делает gRPC таким более гибким, более универсальным. Инструментарий из коробки, там есть аутентификация, потоковая передача данных (в том числе двунаправленная) и много-много других. Ну и, соответственно, сам подход с удаленным вызовом процедур позволяет нам удобно вводить эти процедуры. То есть клиент вызывает такие процедуры, как если бы они были реализованы прямо у него.
Теперь взглянем на формат обмена данными, на protobuf.Это простой бинарный формат, за счет того, что он бинарный, его можно сжать, причём достаточно эффективно, в отличие от того же JSON. И он имеет строгую типизацию в отличие от того же JSON, в котором ты в одном поле можешь в массиве, в запросах, в одном случае передать выражение, в другом - число, в каждом вообще массиве, и строгая типизация всё это не имеет значения. Тем не менее, при отправке данных их необходимо преобразовать в формат protobuf, а клиент должен эти данные уже десериализовать. Но за счет того, что у нас нет такой повторяемости, как в JSON, плюс JSON невозможно эффективно сжимать, а мы получаем большой выигрыш на скорости, очень большой. После того, как мы написали этот самый прото-файл, мы прогоняем его через компилятор и на выходе можем получить код на многих языках программирования, что делает этот инструмент также универсальным, пишем один прото-файл, генерирующий код на разных языках. для микросервисов и в принципе для разработки очень удобно. На последок посмотрим на tRPC - относительно новый инструмент, расшифровывается как конечно, давай объясню, что такое trpc без лишнего пафоса и пункта. trpc расшифровывается как типобезопасный вызов удаленной процедуры, по сути, это способ включения серверных функций с клиентом, так что просто у вас в коде.идея в том, чтобы не писать официальные ручек и не заморачиваться с axios или fetch, и тем более не делать двойную работу с описанием типов. ты просто пишешь функцию на экране, trpc автоматически делает так, что ты можешь включить ее с клиентом напрямую, и при этом сразу получаешь проверку типа из машинописного текста. если ты передал не тот аргумент или забыл поле- тс тебе сразу об этом скажет.всё это работает по принципу маршрутизаторов и процедур(запрос и мутация,напоминает графкл, но без его сложности.).роутер-это как группа функций,объединённая по смыслу. например userRouter или postRouter, процедура-это уже сама функция, которую можно вызвать. например в Англии ты пишешь:

const appRouter = createRouter({ getUser: publicProcedure.input(z.object({ id: z.string() })).query(({ input }) => { return getUserFromDatabase(input.id); }), });

и потом клиенте спокойно вызываешь вот так:

const user = await api.getUser.query({ id: "123" });

без выборки, без ручного разбора, без страха, что что-то, где-то не так-всё типизировано и автодополняется, это просто удобно, особенно когда у тебя большой проект и ты помнишь, чтобы всё было в одном стиле и не разваливалось из простой опечатки. trpc хорошо работает, если у тебя фронт и бэкап на машинописном тексте, например, в next.js. но если сервер на питоне, го или что-то другое - это уже не подойдёт. Это не протокол, не конструкция, не язык-просто библиотека, которая очень ограничивает жизнь, когда клиент и сервер пишутся в одном проекте на одних и тех же типах. всё работает довольно просто и обратно, особенно если ты привык к машинописному тексту и хочешь, чтобы сервер и клиент говорили на одном языке - тогда trpc прям то, что нужно.