Что такое Rest API (http)? Soap? GraphQL? Websockets? RPC (gRPC, tRPC). Клиент - сервер. Вся теория
 Но почему я HTTP-протокол объединила с архитектурным стилем (REST, SOAP) или же, с GraphQL с языком запросов?по сути это вообще разное. И на самом деле они отчасти будут правы.все это объединяет то, что это клиент-серверная архитектура,это всё определяет способ общения клиента и сервера. Про клиент-серверную архитектуру: В такой архитектуре сервер выступает источником, всех вычислений, хранения данных,какой-то бизнес-логики, а клиенты с этим сервером могут взаимодействовать. то есть есть железная машина на котором крутиться наше серверное приложение, которое взаимодействует с базой данных,определяет протоколы взаимодействия,API определяет,и клиент в этой всей архитектуре с помощью каких-то определённых действий может с сервером общаться: может попросить какие-то данные у него, и сервер ему эти данные вернёт. И всё это работает в формате "запрос-ответ", то есть клиент данные попросил - сервер эти данные вернул. И тут не только про данные,мы также можем дать серверу выполнить какое-то действие, например, зарегистрировать нового пользователя или провести оплату или добавить товар в корзину.И соответственно сервер уже определяет, может он выполнить это действие или не может, и в зависимости от этого он будет возвращать разный ответ,то есть сервер выступает как  единым источником вычислений.я в самом начале ошибочно думала, что клиент - это может быть какой-то браузер. Но это и мобильное приложение, и другой сервер, который обращается к нашему серверу, то есть любой и абсолютно любой контакт извне.даже если мы сказали нашему умному дому включить чайник,то это уже то самое. То есть сама аббревиатура "клиент-сервер" подразумевает, что сервер - это поставщик каких-то данных, услуг, логики, а клиент - это потребитель этих данных. А для клиентов сервер - это такое единое, цельное,какое-то монолитное приложение, источник данных. Но при этом сам сервер под капотом может быть большим,распределённым, состоящим из нескольких микросервисов,но при этом клиента это особо не волнует и не должно. Про то, на чём в принципе основан весь веб- это HTTP. HTTP - это гипертекстовый транспортный протокол, который находится на самом верхнем уровне модели OSI,модели TCP/IP - это уровень приложений.Именно с помощью HTTP общаются большинство приложений в интернете. Первоначальная идея HTTP - это обмен гипертекстовыми документами,то есть нашими HTML-ками,но сейчас с помощью HTTP можно по сети передавать практически любые данные: текстовые, файлы, HTML,XML, JSON - в общем, практически любой формат.
По структуре самого HTTP на пример запроса.если разобить HTTP-запрос на составные части и посмотрим на структуру,то первая строчка HTTP-запроса - это стартовая строка, и она из трёх частей:
Метод     URL      Версия HTTP
  !         !           !  
POST     /login      HTTP/1.0


Метод - это, грубо говоря, семантика запроса,то есть что мы хотим конкретно сделать,мы хотим создать какой-то ресурс, обновить его или получить. В данном случае POST говорит о том, что мы хотим какой-то ресурс создать или просто сделать что-то. 
URL - это то, куда мы отправляем запрос. В данном случае мы отправляем его на /login-то есть сервер понимает, какое именно действие мы хотим сделать.
Ну и далее указывается версия HTTP.


следующая часть структуры HTTP - это заголовки (headers).заголовки представляют достаточно важную информацию. В них есть часть заголовков обязательных и часть заголовков необязательных. так же можно составлять какие-то свои кастомные заголовки.
Host:example.com
Content-Type:application/x-www-form-urlencoded;charset=utf-8
Content-Length:26
В них указывается информация о хосте, с которого был отправлен запрос,информация о браузере или о типе устройства, с которого отправляется запрос,тип контента (text/html или какой-то другой тип),также могут отправляться различные авторизационные заголовки с токенами,также  ьлагодаря заголовкам обеспечивается безопасность взаимодействия различных источников сети (CORS - заголовки,которые отвечают за безопасность общения источников, которые расположены на разных доменах).
Третья часть HTTP-запроса,любого HTTP запроса—это самотело сообщения,то есть в нём клиент отправляет серверу какие-то данные, которые ему необходимы, например в сообщении мы отправляем логин пользователя и пароль для того, чтобы сервер мог этого пользователя распознать, то есть клиент отправляет запрос, который выглядит таким образом:
{
    login=user
    password=qwerty
}
,и сервер должен вернуть ему ответ.
    Ответ немного отличается от запроса
HTTP/1.1 200 OK
Content-Type:application/json
Connection:Closed
{
    message:'success login',
    user: {id:'1', username....}
}

стартовая строка выглядит немного по-другому, дело в том, что в ответе стартовая строка она называется "строка статуса",она  содержит версию HTTP,
такой статус-код, который определяет, успешно ли был выполнен запрос. Также в ответе такие же headers заголовки, но они отличаються от тех, которые были в запросе,то есть есть заголовки запроса и есть заголовки ответа и  точно так же есть тело сообщения,в котором сервер возвращает клиенту какие-то данные.HTTP методы-это та самая часть стартовой строки, 
Методов  большое количество, но если только основные, которыми чаще всего оперируют разработчики, методы:
GET-получение ресурса( запросить список товаров, запросить список пользователей,запросить какую-то информацию расширенную по конкретному товару).
POST-передача данных(создание ресурса)(например, auth/login)
PUT-обновление ресурса(PUT и PATCH предназначены для обновления ресурса, но они тоже разные, PUT обновляет ресурс целиком,а
PATCH как правило обновляет только часть ресурса)
PATCH- обновление фрагменита ресурса частично
DELETE- удаление ресурса(удалить пользователя,товар)
 строка статуса, которую возвращает сервер уже в виде ответа. И здесь самой важной частью является статус-код, который сообщает о том,как именно был обработан запрос,есть пять групп этих статус-кодов: Информационные (1xx)—они всегда начинаются с единички (например, 100, 101, 102 и ......). Успешные (2xx)—статус-коды,начинаются с двойки, обозначают, что запрос выполнился успешно. Редиректы (3xx) начинаются с тройки,обычно означают какой-то редирект или перенаправление,например, мы успешно залогинились и нас перенаправляет на другую страницу. Ошибки клиента (4xx)— начинаются с четвёрки,обозначают, что запрос был обработан с ошибкой (например, клиент передал неправильные данные).404 (легендарный статус-код, который говорит о том, что какой-то ресурс не найден) видели все.тот самый легендарный 404 Not Found—когда мы не нашли ресурс, 400 Bad Request - статус-код чаще всего говорит, что запрос был некорректным (то есть опять же это всё про семантику - ничего нам не мешает всегда ставить 400-й статус-код на все клиентские ошибки, но мы их подразделяем) Ошибки сервера (5xx):Server Error(Ошибка сервера)—начинаются с пятёрки—это ошибки сервера (например, клиент передал данные все корректные, но на сервере написали неправильный код,там что-то сломалось,и сервер оответственно возвращает 500-й статус-код).это еще называют "сервер пятисот".500 Internal Server Error—о том, что это внутренняя ошибка сервера. ну и опять же,статус-коды—это про семантику,то есть ничего не мешает нам,на сервере выполнить какое-то действие с ошибкой, но вернуть 200-й статус-код. Но так как я понимаю обычно никто не делает. То же самое и с методами—ничего не мешает сделать так,чтобы GET-запрос создавал какой-то ресурс, а не возвращал какие-то данные,но опять же так никто не делает.
201 Created-говорит об успехе,что ресурс был успешно создан,


REST API - application programming interface
архитектурный стиль, проверенный временем,который сообщает о
том,как наиболее эффективно общаться клиенту и серверу по HTTP,как с
программой стоит общаться.и это интерфейс именно программный.
Допустим, у нас есть программа, обратившись к которой мы можем
сделать следующие действия:
Получить актуальный курс валют,переконвертировать одну валюту в другую,получить прогноз погоды на неделю.Для этого сервер нам должен 
предоставить какой-то интерфейс,с помощью которого мы можем это сделать.мы должны отправить GET-запрос по определённому URL,в 
query-параметрах указать дату, на которую нам нужен прогноз, и город, для которого мы этот прогноз хотим получить. А сервер в 
качестве тела ответа вернётся в виде массива,
состоящего из объектов,в котором есть время,температура,будет ли дождь и  всю необходимую для нас информацию.
И мы видим,что отправив запрос с соответствующими параметрами, мы получим
соответствующий ответ. Это и есть API-то, как мы взаимодействуем с сервером. 


REST API: архитектурный стиль
 это набор правил,который описывает,как использовать HTTP и строить свою API так, чтобы ей было удобно пользоваться, чтобы она выдерживала нагрузки, легко масштабировалась и так далее. То есть чтобы мы извлекали все плюсы. Первая концепция говорит о том, что модель взаимодействия с REST API-это клиент-сервер.API представлена в виде сервера,а  потребителями (клиентами) могут быть как десктопные,браузерные,мобильные приложения, так и другие сервера, которые по какому-то  контракту общаются с нашим сервером. Следующая концепция-многоуровневость или многослойность системы. То есть по REST система может иметь n-ное количество слоёв, причём с  точки зрения клиента это вообще никакой роли не играет.С точки зрения клиента эта вся система она как бы цельная и единая, а внутри там может быть сколько угодно много слоёв с каким-нибудь балансированием, распределением,с какой-нибудь микросервисной архитектурой. Третья концепцияпро то, что сервер не должен обладать каким-либо состоянием (stateless(отсутствие состояния)).пример: клиент отправляет запрос,сервер возвращает ему какой-то ответ,и при этом никакого промежуточного состояния не запоминается (с точки зрения сервера).То есть при каждом следующем запросе клиент и сервер общаются как будто бы в первый раз. Для того чтобы сервер идентифицировал клиента,какие данные вернуть, какую операцию произвести, клиент отправит всю необходимую информацию для того,чтобы сервер смог его обработать и выполнить.Это одна из самых важных концепций.  Четвёртая концепция-это единообразный(унифицированный) интерфейс которым API обладает.у нас интернет-магазин. Над любыми товарами мы можем выполнять CRUD-операции (Create, Read, Update, Delete),то есть добавить товар,удалить товар,обновить информацию,получить список товаров(массив) и по ID  получаем информацию именно по конкретному товару Как с такими операциями взаимодействовать? есть HTTP-методы POST, DELETE, PUT, PATCH и GET и каждый из этих методов обладает определённой семантикой POST-создание,DELETE-удаление,PUT/PATCH-обновление,GET-получение То есть для каждой CRUD-операции мы используем HTTP-метод,для каждой сущности у нас есть определённый URL, по которому мы с ней взаимодействуем. В данном случае для товаров это URL----   /products Если мы хотим получить информацию по конкретному товару, то у нас в конце добавляется ещё ID------  /products/{id}. Вот именно такая работа со всеми endpoint'ами и есть тот самый единообразный,унифицированный интерфейс. Сюда же можно ещё добавить формат взаимодействия (JSON, XML), заголовки, которые требуются для авторизации пользователя (какой-нибудь токен).и например такого по типу что в одном заголовке может быть authorisation_token,x-token, то есть все должно быть единообразным и в одном едином логическом стиле которое диктует REST API,то есть сам запрос должен содержать все что нужно по информации чтобы его выполнить. Мы не можем просто взять и сказать серверу "создай товар",просто отправив POST-запрос. Мы должны предоставить всё необходимое, нам нужно дать серверу все что требуется, чтобы он этот товар смог создать. То есть помимо самого POST-запроса мы указываем информацию о товаре в теле запроса,соответствующие заголовки, метод, соответствующий URL,и только тогда,сервер сможет этот запрос обработать- это семантика,то есть,с помощью GET-запроса мы должны получать данные, а изменять, удалять или создавать мы не должны. Хотя в теории,чисто технически мы можем так сделать-ничего не мешает нам вообще использовать на всё GET-запросы и любую операцию делать через них,HTTP это позволяет,но семантика REST- это как раз про наиболее эффективное использование HTTP и мы нарушим, если будем использовать GET для изменения данных. в PUT всё немного сложнее. Есть такое понятие как идемпотентность запросов. Причём какие-то запросы считаются идемпотентными, а какие-то априори не могут быть таковыми. Идемпотентность, метод HTTP-считается идемпотентным, если повторный запрос, сделанный несколько раз подряд и имеет один и тот же эффект. То есть если мы пытаемся обновить  ресурс и отправляем один и тот же запрос с одинаковыми данными на обновление, то сервер должен выполнить этот запрос одинаково,не должно быть такого,что первый запрос сделал одни действия,второй запрос сделал другие действия.идемпотентность-это свойство,которое означает,что повторно идентичный запрос,сделанный несколько раз подряд, имеет один и тот же эффект и не изменяет состояние сервера. Корректно реализованные методы GET, PUT и DELETE идемпотентны.Но вот POST, например, идемпотентным по своей природе быть не может,и если мы отправим POST-запрос с одинаковыми данными несколько раз подряд,сервер создаст у нас несколько разных ресурсов. То есть результат здесь уже отчасти предсказуемый,но не совсем-ресурсы всё равно создаются разные,эффект происходит не один и тот же. Именно поэтому POST-запрос не идемпотентен.теперь на примере PUT-запроса. Если мы меняем возраст у какого-то ресурса (например,юзера) с 10 на 20,а потом ещё отправим такой же PUT-запрос с попыткой заменить возраст на 20, у нас ничего не произойдёт,сервер не создаст нового ресурса, не удалит его-он просто обновит тот же самый атрибут у какой-то сущности. Кэширование. Причём кэширование может быть осуществлено средствами HTTP (за счёт проставления определённых заголовков),так и средствами какими-то сторонними, реализованными на сервере (использование например Redis,Memcached и так далее). Причём важный момент с точки зрения семантики:
GET и POST-запросы могут кэшироваться,а PUT и DELETE-не могут  и что вообще кэширование подразумевает.у нас есть сервер и миллион клиентов одновременно (или с каким-то промежутком времени) запрашивают у нас список валют с помощью GET-запроса,но список валют меняется крайне редко,и каждый раз полноценно отправлять запрос, полноценно залазить в базу данных,доставать этот список валют,чтобы вернуть его клиенту-смысла особого не имеет. Поэтому мы можем иметь кэш. Этот кэш может быть реализован с помощью HTTP-заголовков, и результаты этого кэша будут храниться прямо в браузере, либо с помощью каких-то сторонних систем,которые реализованы на сервере (например Redis),на пример мы указали, что хотим кэшировать результат, сохранили где-то его в браузере, теперь в следующий раз, когда наш клиент запрашивает список валют, мы смотрим,что он у нас находится уже в кэше, и не отправляем запрос на сервер повторный, а достаём из кэша.То есть это происходит намного быстрее,и как побочный эффект -снижает нагрузку на сервер.можно там сказать какую-то команду для нашего умного дома--"включи свет" и свет у вас включится,то есть своего рода такая оптимизация вашего времени. Вот с кэшом в принципе то же самое -мы не ходим каждый раз в базу данных,не отправляем каждый раз запрос, а достаём данные, которые редко меняются, из этого кэша. про формат обмена данными между клиентом и сервером. по REST можно обмениваться практически любыми данными, но в большинстве своём это JSON. Но также бывает и используется и XML.в финтех,банковской сфере XML достаточно распространён.Следующий важный момент- это версионирование,представим ситуацию, что у нас есть какой-то набор эндпоинтов, мы с ним работаем. У нас есть какие-то клиенты, которые эти эндпоинты используют, и в какой-то момент нам необходимо внести какие-то правки в нашу API,но эти правки не обратно совместимы. То есть, например, мы хотим убрать вообще метод удаления пользователя или как-то изменить формат общения и если сделать это прямо в текущем коде, в текущей версии API, то у всех клиентов которые с нами работают,всё сломается. Но все прекрасно понимают,что все правки,которые мы вносим, должны быть обратно совместимыми. И конечно, когда вы вносите вот такие вот правки которые как-то меняют формат данных,надо менять именно версию,те пользователи, которые работают с первой версией API, они так и продолжают с ней работать, а новые пользователи или пользователи,которые хотят сделать миграцию,начинают работать с новой версии-со второй, третьей, четвёртой, пятой и тд.

Документация вашей API. Опять же, это не свойственно именно REST, это свойственно в принципе любому API.Но у REST есть даже определённые спецификации,потому как стоит документировать и описывать ваше API и здесь вспоминаем про OpenAPI-это спецификация и Swagger. OpenAPI - это спецификация, которая позволяет задокументировать API,то, какие у вас есть эндпоинты, какие методы, какие статус-коды, какие query-параметры ожидаются на вход, какое тело запроса,какое тело ответа будет возвращено,какие ошибки должны нами быиь обработаны и так далее,версия API в том числе. В общем, всю-всю-всюююююю необходимую информацию для того, чтобы мы с этой API смогли начать работать. Про Swagger. Swagger по сути это имплементация OpenAPI,это такой себе набор инструментов для документации и визуализации нашего REST API.В большинстве своём на всех языках программирования,в фреймворках есть инструментарий,который позволяет автоматически, почти без каких-либо дополнительных действий, генерить на основе ваших эндпоинтов всю документацию а вы можете только как-то дополнять.
СОУУУУУ......
модель взаимодействия по REST - это клиент-сервер. 
Система может быть многоуровневой или многослойной
Также REST не должно обладать каким-то состоянием-каждый раз клиент и сервер общаются как в первый раз.
Должно обладать единообразным унифицированным интерфейсом. 
Также API может кэшироваться. 
формат обмена данными чаще всего JSON. 
API должна быть версионирована,в идеале конечно,ваша API должна быть задокументирована.
REST - это не протокол, это архитектурный стиль,набор правил а в свою очередь, SOAP-это уже протокол обмена структурированными сообщениями и если в REST у нас может быть любой формат данных\-JSON, XML либо какой-то ещё, то в SOAP это  только XML и XML только   -SOAP XML со своей спецификой. При этом,никто не запрещает вам в рамках одного приложения, в рамках одного сервера,одного бэкенда реализовать и REST и SOAP.То есть у вас бизнес-логика-это какое-то отдельное ядро,есть  REST-контроллеры, которые возвращают JSON, есть SOAP-контроллеры, в которых описан WSDL и которые возвращают XML. Если REST - это набор правил по эффективному использованию HTTP, то SOAP в свою очередь может использоваться с любым протоколом прикладного уровня: SMTP, FTP, HTTP и другие. Для описания SOAP-сервисов используется WSDL(Web Service Description Language) - это определённый язык, который основан на XML.Здесь нет эндпоинтов в классическом понимании как в REST, здесь есть так называемые операции.Например у нас есть какой то GET и у него есть INPUT,который мы ожидаем на входе  и OUTPUT то что будет выдано на выходе.Просто есть такой зык WSDL и с помощью него описываються SOAP сервисы. REST  при сравнении это как множество окошек в которые мы можем постучать или множество дверей которые мы можем открыть. В свою очередь, SOAP - это скорее одно окно, вкоторое нам необходимо передать название процедуры, название операции, которую мы хотим выполнить. SOAP в отличие от REST обладает определённой строгостью, потому что REST- это всё-таки какой-то набор правил,архитектурный стиль а SOAP - это уже протокол,который задаёт определённые рамки, определённые границы. И сообщения, которые отправляются в SOAP, обладают определённой структурой.
Четыре частим этой структуры: три обязательных и одна опциональная (она отвечает за ошибки).

Envelope-это корневой элемент, который определяет начало и конец сообщения и именно благодаря нему клиент понимает, когда сообщение полностью получено. 
Header-это что-то типа заголовков в обычном HTTP-запросе,он даёт нам возможность определять какие-то дополнительные свойства для приложения,например,
      отправить какой-то токен, указать тип формата сообщения и любую другую вспомогательную информацию. 
Body(тело)-в котором мы передаём уже какую-то полезную нагрузку,какие-то полезные данные. 

REST- это просто набор рекомендаций в целом со свободной структурой, и SOAP в свою очередь - это уже протокол, который определяет строгие правила,строгую структуру и загоняет нас в определённые границы. Здесь описываются сервисы с помощью WSDL, и  обмена сообщениями происходят в формате XML. Часто SOAP используется в банковской сфере.

GraphQL - язык запросов.GraphQL - это уже не архитектурный стиль и не протокол, это язык запросов,например у нас магазин электроники и здесь есть страница детального просмотра информации по конкретному товару,здесь запрашивается много данных: всякие характеристики, описания, стоимость в общем много-много всего по конкретному товару,также у нас есть другая страница, где мы отображаем товары уже списком,и здесь нам необходимо запросить мало данных.То есть нам достаточно отобразить модель товара,его рейтинг и стоимость. или например, какая-нибудь админка, где нам нужно отобразить данные в виде например таблицы какой-нибудь для админов. И там нам нужно уже больше данных,иииии вот, при классическом подходе нам бы пришлось делать следующее: либо у нас был бы один endpoint, который возвращал бы массив абсолютно всех данных, которые нам нужны,то есть объект со всеми вложенными полями, которые нам даже могут быть в конкретном запросе не нужны, либо же нам на бэкенде бы делать разные эндпоинты как "Little Data", "Big Data"(конечно так никто не называет, это просто для примера),то есть в одном запросе мы возвращаем нужные данные для одной страницы,в другом запросе- нужные данные для третьей страницы, для четвёртой и тд,но это не оптимальный подход, и хотелось бы иметь возможность, чтобы клиент сам определял, какие данные ему в конкретном месте нужны,схематично мы хотим иметь какую-то такую картину: клиент отправляет запрос за продуктами, за товарами и говорит: "Дай мне данные с идентификатором, названием и стоимостью", и на сервере все лишние данные,характеристики отбрасываются,и возвращаются товары только с теми полями,которые мы запросили. И вот GraphQL как раз для этого ипредназначен,если при классическом подходе сервер определяет схему и формат данных,которые возвращаются в конкретном эндпоинте,то в GraphQL сервер как раз определяет только схему данных, а клиент уже сам запрашивает те данные,поля и характеристики,те атрибуты,которые ему требуются. В одном запросе нужно три поля из объекта-запрашиваем три. В другом нужно 53-значит, можем запросить все 53 поля.  В GraphQL есть два основных вида запроса: это Query и Mutation. 
Query-это аналог GET-запроса. 
Mutation -это аналог POST-запроса. 
То есть с помощью Query мы какие-то данные получаем,с помощью Mutation либо создаём либо меняем. Также
есть ещё Subscription-это realtime какие-то изменения,своего рода подписка на изменения данных.
Подписки сделаны поверх WebSockets 
В первую очередь ---- описывается схема данных. В принципе, это похоже на обычные интерфейсы,где просто описываются поля и тип этих полей. После того как мы описали схему,сделали какую-то логику на бэкенде,с фронта мы можем запрашивать данные например у user мы запрашиваем только одно поле-name,также мы можем запрашивать какие-то вложенные данные,например, у каждого user есть массив friends,и также вложенные какие-то поля - только те, что нам нужны, мы можем запросить. На вход в запрос можно передавать какой-то Input-это будут аргументы,например, мы можем указать, что мы хотим получить человека с id= 1000 и хотим запросить name и height при этом какие-то часто запрашиваемые поля мы можем вынести в так называемые Fragments и использовать их в разных запросах. То есть это сделано для того,чтобы мы могли какие-то части не описывать каждый раз заново,а переиспользовать в одном месте, в другом месте ну ииии ...... 
Mutation-это по сути тоже обыкновенный запрос, но который
как-то данные мутирует: изменяет, создаёт что-то, выполняет какое-то действие, обновляет какую-то сущность и так далее.К примеру есть какой-то Input на входе,мы там указываем поля которые мы хотим получить в качестве тела ответа, и соответственно отправляем запрос и бекенд-нам возвращает только нужные данные. Работает это по сути точно так же: запрашиваем
нужные данные,отправляем Mutation и сервер нам нужные данные возвращает. Допустим есть у нас User у которого есть список каких-то постов, есть отдельно описанный
тип Post.описываються Inputs- это то, что мы ожидаем на вход,описываются соответственно все типы,описываются Queries,описываются Mutations. Описывается то,что мы ожидаем на вход и то, что возвращают все эти Queries или эти Mutations.То есть getAllUsers возвращает массив пользователей, getUser возвращает по id конкретного пользователя, и mutation createUser.Далее описываются сами эндпоинты, бизнес-логика какая-то,то есть  мы например по id пользователя находим, возвращаем всех пользователей,пользователя создаём,
добавляем его в массив,присваиваем какой-то идентификатор,с базой данных взаимодействуем. Потом указываем URL,по которому будет всё это дело доступно, указываем схему и запускаем сервер. И далее по такому вот пути, который мы указали  нам будет доступна своего рода админка,то есть мы можем посмотреть все запросы, все мутации, посмотреть какого типа у нас данные и что удобно-это всё отдаётся фронту,и фронт сам определяет, какие данные ему нужны.Соответственно, он может запрашивать только то, что требуется ему в конкретной ситуации. Также всё можем посмотреть по мутациям, поискам-то,что нам необходимо найти.при этом мы так же можем написать какой-то запрос и при чем что важно- в одном запросе мы можем запрашивать разные данные,то есть мы можем делать комбинированные запросы. к примеру указываем запрос за получением списка всех пользователей,и мы хотим от бэкенда получить id,username,отправляем запрос и мы можем видеть что нам вернул эндпоинт,мы можем попробовать  запросить только id,попробуем запросить ещё какую-нибудь вложенную сущность, например dishes и title. 
А теперь преимущества, которые GraphQL нам предоставляет:

Это частичная самодокументируемость за счет строгой схемы

Все Inputs,OUTPUTS,Query,Схему,типы,документации -это все типы-это всё частично самодокументируется. 
Схема - это кодогенерируемая. Опять же за счёт строгой схемы мы можем генерировать в том числе и на фронтенде код. Флоу работы здесь следующий: мы описываем какой-то запрос, например, получить список всех todo-шек с такими-то полями,далее запускаем определённый скрипт с помощью определённого инструмента и указываем путь до схемы,после чего, во-первых, в базовом варианте нам нагенерируют автоматически все типы.Нам не придётся описывать их вручную,и у нас будет ну практически полное соответствие типов на фронтенде и на бэкенде. Но также это дело всё можно ещё по-тюнинговать и сгенерировать например endpoint-ы для RTK Query, генерировать запросы для React Query В или просто запросы с заданным набором параметров,в  общем, это тоже достаточно классная фича GraphQL. Следующее преимущество - это  наверное, оно самое основное - это то, что клиент запрашивает только нужные ему данные.
Из этого вытекает как раз то,что меньше трафика гоняется по сети. Мы не запрашиваем огромный набор данных,мы можем запросить только то,что нам нужно в конкретной ситуации.Это влияет,и на скорость работы и на трафик который потребляется клиентом.В общем, сплошные плюсы.


Вебсокеты - это также протокол,но в отличие от http,в котором мы установливаем связь,отправляем какой-то запрос,получаем ответ и связь обрываем,то здесь устанавливается постоянное подключение.В http, конечно,бывают исключения, в realtime приложениях например, но в классическом варианте всё-таки на каждый запрос устанавливается новое соединение в http. 
Websocket - это как раз протокол для realtime взаимодействия,когда клиент и сервер за счёт постоянного соединения непрерывно обмениваются какими-то данными.
Когда нужны вебсокеты? Это,конечно же, какие-нибудь чаты,где вы непрерывно обмениваетесь сообщениями,это графики,где нужно быстро показывать изменения, например, там курсы валют или на бирже, когда цены на акции меняются постоянно в realtime.
Начну с HTTP: похожая схема-есть сервер, который с базой данных общается,мы отправляем запрос,получаем ответ,и на этом соединение обрывается.При этом, если подразумевается какая-то широковещательная рассылка,например,отправка сообщения в чат,то для того,чтобы остальные пользователи получили это сообщение,они должны его запросить,то есть отправить повторный запрос.В вебсокетах это работает немного по-другому: все,грубо говоря, онлайн-пользователи устанавливают соединение с сервером-это непрерывное соединение,в котором и клиент,и сервер постоянно обмениваются какими-то сообщениями. И уже в данном случае, если один пользователь отправляет сообщение на сервер,то сервер со всеми,с кем у него установлено подключение, может сразу этим сообщением поделиться (так называемая широковещательная рассылка). И за счёт того, что нам не надо постоянно устанавливать соединение и обрывать это соединение, клиент с сервером могут в таком непрерывном формате обмениваться сообщениями вот в таком двустороннем формате. И есть 4 realtime-чата на практике на разных технологиях: это WebSocket(вебсокеты), это long polling и Server-Sent Events,Short Polling . Как вебсокеты вообще работают. Например у нас есть простой сервер: простейший websocket-сервер, вешаем handler на подключение и на сообщение (это события), и эти сообщения мы как-то обрабатываем. Отправляем с клиента поле event,по которому мы определяем,какое действие должно выполниться: подключение или же отправка сообщения. Также у нас может быть широковещательная рассылка,где мы по всем онлайн-клиентам можем пройтись в цикле и отправить им сообщение.Теперь на клиент: устанавливаем соединение (но вместо http указываем ws-это протокол),указываем порт и подключаемся. Только в отличие от http мы не на каждом запросе это указываем, только при подключении.и также у нас можеть быть события onOpen, onMessage, onClose и onError и каждое из этих событий мы можем обработать и написать на это какую-то логику: отправка сообщения, установка подключения, закрытие подключения. 
Про удалённый вызов процедур (RPC), в частности про gRPC и tRPC. понятие RPC-это удалённый вызов процедур,у нас есть клиент и есть сервер. Сервер реализует какой-то метод,например, client.stub.doSomething() или "добавить в корзину" или ещё какое-то действие. При этом на клиенте этот метод не реализован, но клиент с помощью специального объекта (так называемого стаба) может этот метод вызвать,и при этом он это делает так, как будто бы этот метод реализован у него.То есть это и есть удалённый вызов процедуры: на самом деле там отправляется сетевой запрос,сервер отправляет какие-то данные,но с точки зрения клиента это всё происходит так,как будто бы клиент сам вызвал эту процедуру и сам выполнил какое-то действие,происходит именно вот такое удалённое взаимодействие,то есть сервер имплементирует какой-то метод (с точки зрения RPC это называется процедура), и клиент эти процедуры удалённо может вызвать. При этом с точки зрения его кода это выглядит как stub.названиеПроцедуры() или  метода.звучит достаточно удобно.

Про gRPC.
gRPC - это как раз фреймворк ,набор инструментов, платформа от Google(Исходный код открыт в 2015 году), и внутри себя она использует как раз вот эту технологию удалённого вызова процедур. gRPC очень популярен в микросервисной архитектуре, и вот именно микросервисы друг с другом по gRPC общаются.например, во всей вот этой схеме микросервисы между собой общаются по gRPC, есть какой-то proxy/gateway, какая-то входная точка, которая может уже всё это по REST API отдавать куда-то в веб, в мобилку и так далее,но сами вот эти микросервисы они общаются по gRPC, делают это супер эффективно и супер быстро за счёт преимуществ HTTP2 и других преимуществ.Что отличает gRPC от классического подхода. Во-первых, здесь используется HTTP2 вместо HTTP 1/1. HTTP2 по тестам быстрее на 10-15%,чем HTTP1/1.Вместо текстовых сообщений, которые используются в HTTP1/1,в HTTP2 используется бинарный формат,за счёт этого его можно лучше сжать,лучше обработать, быстрее отправить. В HTTP2 также реализованы потоки данных(стриминг), он простой и супербыстрый. Также здесь вместо JSON,который достаточно избыточный и не сжимается,используется бинарный формат, он называется protobuf,Также в gRPC есть инструментарий из коробки: это генерация кода для многих языков программирования.То есть вы описываете определённый файлик,указываете, что на входе, что на выходе, какие процедуры у вас есть 
внутри сервиса,и с помощью специального генератора (специального компилятора,который называется protoC) вы можете сгенерировать код для разных языков программирования. Это тоже делает gRPC таким более гибким, более универсальным инструментом.инструментарий из коробки,там есть аутентификация,потоковая передача данных(в том числе двунаправленная) и много-много другого.Ну и,соответственно, сам подход с удалённым вызовом процедур,позволяет нам удобно эти процедуры вызывать. То есть клиент вызывает процедуры так,как будто бы они реализованы прямо у него.  
Теперь   взглянем на формат обмена данными, на protobuf.Это простой бинарный формат,за счёт того, что он бинарный, его можно сжать, причём достаточно эффективно,в отличие от того же JSON.И он имеет строгую типизацию в отличие тоже от того же JSON,в котором ты в одно поле можешь в массиве,в объектах,в одном случае передать строку,в другом - number,в третьем вообще массив, и строгой типизации это всё не имеет.Но есть нюанс с тем, что сервер перед тем, как отправить данные, должен их сериализовать в формат protobuf,а клиент должен эти данные уже десериализовать. Но за счёт того, что у нас нет такой избыточности, как в JSON, плюс JSON нельзя сжимать эффективно, а мы получаем большой выигрыш в скорости,очень большой.то есь выглядит это как сервис с двумя процедурами, у которых на вход мы ожидаем HelloRequest, а на выходе HelloReply. После того, как мы описали этот самый proto-файл,мы прогоняем его через компилятор и  на выходе можем получить код на многих языках программирования, что делает этот инструмент также универсальным, пишем один proto-файл, генерим код на разных языках. для микросервисов и в принципе для разработки супер удобно.
Напоследок посмотрим на tRPC - относительно новый инструмент, расшифровывается как конечно, давай объясню что такое trpc без лишнего пафоса и пунктов. trpc расшифровывается как typesafe remote procedure call-по сути это способ вызывать серверные функции с клиента так будто они просто у тебя в коде.идея в том чтобы не писать кучу ручек и не заморачиваться с axios или fetch и тем более не делать двойную работу с описанием типов. ты просто пишешь функцию на сервере,trpc автоматически делает так что ты можешь вызывать её с клиента напрямую и при этом сразу получаешь проверку типов от typescript. если ты передал не тот аргумент или забыл поле- ts тебе сразу об этом скажет.всё это работает по принципу роутеров и процедур(query и mutation,напоминает graphql, но без его сложности.).роутер-это как группа функций, объединённых по смыслу. например userRouter или postRouter,а процедура-это уже сама функция,которую можно вызвать.
например на сервере ты пишешь:

const appRouter = createRouter({
  getUser: publicProcedure.input(z.object({ id: z.string() })).query(({ input }) => {
    return getUserFromDatabase(input.id);
  }),
});


и потом на клиенте спокойно вызываешь это вот так:


const user = await api.getUser.query({ id: "123" });

без fetch, без ручного парсинга,без страха, что что-то, где-то не так-всё типизировано и автодополняется,это просто удобно,особенно когда у тебя большой проект и ты хочешь, чтобы всё было в одном стиле и не разваливалось от простой опечатки.
trpc хорошо работает если у тебя фронт и бэк на typescript,например с next.js. но если сервер на питоне, го или чём-то другом-это уже не подойдёт.Это не протокол, не стиль архитектуры, не язык-просто библиотека которая очень упрощает жизнь когда клиент и сервер пишутся в одном проекте на одних и тех же типах.всё работает довольно просто и интуитивно, особенно если ты привык к typescript и хочешь чтобы сервер и клиент как бы говорили на одном языке - тогда trpc прям то что нужно.

